{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-throughput data matrix reading for COVID-19 testing in Singapore\n",
    "\n",
    "Minimum viable product would be a Python package that you can install on your computer. If successful, there's potential to deploy as a web app on a server. I think there's potential for use on mobile platforms, take picture and upload.\n",
    "\n",
    "To host this as a web app, a few options are available:\n",
    "- MEAN stack\n",
    "- Flask/Bottle\n",
    "- Onsen\n",
    "\n",
    "There's a bug regarding [bounding box generation](https://github.com/NaturalHistoryMuseum/pylibdmtx/issues/51). Makes me wonder if it's worth fixing the bug, or segmenting the image, and processing them separately. I decided on the latter.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "See below, along with the regular NumPy, matplotlib libraries. I recommend installing the Python flavour of OpenCV rather than using the bare distributions. You will need to install the libdmtx package using your system package manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pylibdmtx.pylibdmtx import decode\n",
    "from PIL import Image\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Contour Detection\n",
    "### Image preprocessing\n",
    "\n",
    "We'll use contours and bounding rectangles to segment out areas of interest after some basic image preprocessing.\n",
    "\n",
    "First, we’ll convert the image to grayscale and will perform a Gaussian blur on it to simplify it and to remove noise.\n",
    "\n",
    "Then, we'll perform a binary threshold on the preprocessed image. Since the data matrices are pasted on white circles on the sample tubes, I postulate the threshold can pick up the lighter circles as features of interest in the image.\n",
    "\n",
    "**Future work.** Might have to look into adaptive thresholding to deal with images with variable lighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=400).patch.set_facecolor('white')\n",
    "\n",
    "samples = cv2.imread('images/3.jpeg')\n",
    "samples_grey = cv2.cvtColor(samples, cv2.COLOR_BGR2GRAY)\n",
    "plt.subplot(131); plt.title('greyscale'); plt.axis('off'); plt.xticks([]); plt.yticks([])\n",
    "plt.imshow(samples_grey, cmap = plt.cm.gray)\n",
    "\n",
    "samples_gaussian = cv2.GaussianBlur(samples_grey, (5, 5), 0)\n",
    "plt.subplot(132); plt.title('gaussian'); plt.xticks([]); plt.yticks([])\n",
    "plt.imshow(samples_gaussian, cmap = plt.cm.gray)\n",
    "\n",
    "_, samples_binary = cv2.threshold(samples_gaussian, 170, 255, cv2.THRESH_BINARY)\n",
    "plt.subplot(133); plt.title('binary'); plt.xticks([]); plt.yticks([])\n",
    "plt.imshow(samples_binary, cmap = plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding contours and constructing bounding rectangles\n",
    "\n",
    "Now that simplified, binary versions of the image are available, we can use them to identiy feastures of interest. Using the provided functions in OpenCV, we'll find the contour of each coin. Using the `cv2.RETR_EXTERNAL` flag to the function returns only the external contours, which is the largest circle formed by the data matrix sticker. This prevents the algorithm from picking up on the smaller contours inside the data matrix pattern.\n",
    "\n",
    "In addition, I also set a minimum and maximum size to limit the number of contours to a reasonable figure.\n",
    "\n",
    "If it doesn't work, I'll play with the binary threshold parameters in the previous step to get better segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=400).patch.set_facecolor('white')\n",
    "\n",
    "samples_contours, _ = cv2.findContours(samples_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "samples_and_contours = np.copy(samples)\n",
    "\n",
    "min_area = 1000 # 1000\n",
    "max_area = 1100 # 60000\n",
    "large_contours = [cnt for cnt in samples_contours if cv2.contourArea(cnt) < max_area]\n",
    "final_contours = [cnt for cnt in samples_contours if cv2.contourArea(cnt) > min_area]\n",
    "\n",
    "cv2.drawContours(samples_and_contours, final_contours, -1, (255,0,0))\n",
    "plt.subplot(131); plt.title('contours'); plt.axis('off'); plt.xticks([]); plt.yticks([])\n",
    "plt.imshow(samples_and_contours)\n",
    "\n",
    "bounding_img = np.copy(samples)\n",
    "\n",
    "box_coordinates = []\n",
    "\n",
    "c = 0\n",
    "for contour in final_contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    box_coordinates.append([x, y, w, h])\n",
    "    cv2.rectangle(bounding_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "plt.subplot(132); plt.title('bounding_box'); plt.axis('off'); plt.xticks([]); plt.yticks([])\n",
    "plt.imshow(bounding_img)\n",
    "print('number of samples: %d' % len(final_contours))\n",
    "    \n",
    "col_sort = sorted(box_coordinates, key=lambda l:l[1])\n",
    "\n",
    "# these are actually important constants, my implementation of auto-detection for grids is sketchy at best\n",
    "row_length = 9\n",
    "col_length = 9\n",
    "col_taken = math.ceil(int(len(col_sort) / col_length)) + 1\n",
    "\n",
    "labeled_img = np.copy(samples)\n",
    "\n",
    "for i in range(col_taken):\n",
    "    row = sorted(col_sort[i * col_length : i * col_length + row_length])\n",
    "    for k, _ in enumerate(row):\n",
    "        cv2.putText(labeled_img, f\"({k}, {i})\", (row[k][0], row[k][1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "    \n",
    "plt.subplot(133); plt.title('labeled'); plt.axis('off'); plt.xticks([]); plt.yticks([])\n",
    "plt.imshow(labeled_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving bounding rectangles as separate, labeled images\n",
    "\n",
    "Now that we know this method works, at least for this image, we can work on saving the bounding rectangles as separate images, to be processed by libdmtx. It's nearly the same code as above, but instead of writing the grid coordinates into an image, we extract it, and save it as a file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(col_taken):\n",
    "    row = sorted(col_sort[i * col_length : i * col_length + row_length])\n",
    "    for k, _ in enumerate(row):\n",
    "        # data_matrix = samples[row[k][1]:row[k][1]+row[k][3], row[k][0]:row[k][0]+row[k][2]]\n",
    "        data_matrix = samples[row[k][1]:row[k][1]+row[k][3] + 1, row[k][0]:row[k][0]+row[k][2] + 1]\n",
    "        cv2.imwrite(f'output/{k}_{i}.jpg', data_matrix)\n",
    "        \n",
    "def display_multiple_img(images, rows = row_length, cols = col_length):\n",
    "    os.chdir('output')\n",
    "    figure, ax = plt.subplots(nrows=rows,ncols=cols,dpi=400)\n",
    "    figure.patch.set_facecolor('white')\n",
    "    for i, image in enumerate(images):\n",
    "        ax.ravel()[i].imshow(cv2.imread(image))\n",
    "        ax.ravel()[i].set_title(image)\n",
    "        ax.ravel()[i].title.set_fontsize(4)\n",
    "        ax.ravel()[i].set_axis_off()\n",
    "    for i in range(len(images), (rows*cols)):\n",
    "        ax.ravel()[i].set_axis_off()\n",
    "    \n",
    "    os.chdir('..')\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.05, hspace=1.0)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "images = [x for x in sorted(os.listdir('output'), key = lambda k: [k[2], k[0]]) if x.endswith('.jpg')]\n",
    "\n",
    "display_multiple_img(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data matrix codes\n",
    "\n",
    "Here comes the simple part, hopefully everything works well with the library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_matrix(image_list):\n",
    "    os.chdir('output')\n",
    "    a = []\n",
    "    for i in image_list:\n",
    "        e = decode(cv2.imread(i),max_count=1)\n",
    "        try:\n",
    "            print(e[0][0], i)\n",
    "        except IndexError:\n",
    "            print('error', i)\n",
    "        a.append(e)\n",
    "    print(f'Images parsed: {len(a)}')\n",
    "    os.chdir('..')\n",
    "    # return info_dict\n",
    "\n",
    "read_data_matrix(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Edge Detection with the Hough Circle Transform\n",
    "\n",
    "Sometimes segmenting via color or intensity as we did with binary thresholding isn’t sufficient. What if we have to deal with variations of lighting intensity? There may be cases where the white circles representing the stickers aren't uniform throughout.\n",
    "\n",
    "Edges are points in an image where there is a change in brightness or intensity, which usually implies a boundary between different objects. The [Canny edge detection algorithm](https://www.wikiwand.com/en/Canny_edge_detector) is a popular edge detection algorithm that produces accurate, clean edges.\n",
    "\n",
    "After we process the image with the above algorithm, the [Hough Circle Transform](https://en.wikipedia.org/wiki/Circle_Hough_Transform) can be used to detect circles of variable size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_matrix(image_list):\n",
    "    os.chdir('output')\n",
    "    a = []\n",
    "    for i in image_list:\n",
    "        e = decode(cv2.imread(i)[:, :, :1],max_count=1)\n",
    "        print(e, i)\n",
    "        a.append(e)\n",
    "    print(len(a))\n",
    "    os.chdir('..')\n",
    "    # return info_dict\n",
    "\n",
    "read_data_matrix(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_coords = []\n",
    "bounding_coordinates\n",
    "\n",
    "for i in bounding_coordinates:\n",
    "    y_coords.append(i[1])\n",
    "    \n",
    "inxi = sorted(y_coords)\n",
    "\n",
    "m = 0\n",
    "total = 0\n",
    "for i in range(len(inxi) - 1):\n",
    "    d = inxi[i + 1] - inxi[i]\n",
    "    if d > m:\n",
    "        m = d\n",
    "    print(d)\n",
    "    total += m\n",
    "\n",
    "avg = total / len(inxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 1\n",
    "for i in range(len(inxi) - 1):\n",
    "    d = inxi[i + 1] - inxi[i]\n",
    "    if d > (avg / 2):\n",
    "        col += 1\n",
    "\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = decode(Image.open('images/3.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i[1].rect.left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = decode(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(70/8) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholding stuff\n",
    "\n",
    "p = plt.imread('images/3.jpeg')\n",
    "p = cv2.cvtColor(p, cv2.COLOR_RGB2GRAY)\n",
    "#plt.subplot(151); plt.title('greyscale'); plt.imshow(p)\n",
    "\n",
    "x, thr = cv2.threshold(p, 60, 255, cv2.THRESH_BINARY)\n",
    "thr = thr.astype('uint8')\n",
    "plt.figure(dpi=1200)\n",
    "plt.plot(); plt.title('threshold')\n",
    "plt.imshow(thr, cmap = plt.cm.gray)\n",
    "plt.savefig('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding bounding rectangles\n",
    "image = Image.open('images/1.jpeg')\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "for matrix in decode(image):\n",
    "    rect = matrix.rect\n",
    "    draw.rectangle(((rect.left, rect.top), (rect.left + rect.width, rect.top + rect.height)),outline='Aquamarine')\n",
    "    \n",
    "image.save('bounding_1.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
